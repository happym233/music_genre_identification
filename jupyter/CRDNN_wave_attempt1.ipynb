{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed839cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7679d887",
   "metadata": {},
   "source": [
    "## switch to the root dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "119057d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.gitignore',\n",
       " '.idea',\n",
       " 'data_loader',\n",
       " 'data_processor',\n",
       " 'jupyter',\n",
       " 'loggers',\n",
       " 'main.py',\n",
       " 'models',\n",
       " 'original_data',\n",
       " 'processed_data',\n",
       " 'README.md',\n",
       " 'saved_models',\n",
       " 'trainers']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce36ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processor.utils import load_numpy_arrays, numpy_to_tensor\n",
    "from models.CNN import CNN_2d_block\n",
    "from models.MLP import MLP\n",
    "import trainers.SGD_trainer\n",
    "from loggers.statistics_loggers import plot_numerical_arrays\n",
    "import torch\n",
    "from torch import nn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae8ecd3",
   "metadata": {},
   "source": [
    "## Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ba659b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = load_numpy_arrays(['data_train_X.npy','data_train_y.npy', 'data_val_X.npy','data_val_y.npy']\n",
    "                  , path_prefix='processed_data/processed_waves/4-genres/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18aeb11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_val, y_val = numpy_to_tensor([X_train, y_train, X_val, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02f61a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.type(torch.int64)\n",
    "y_val = y_val.type(torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "744b5eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([640, 501, 20])\n",
      "torch.Size([640])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64261ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.6793, -3.5519, -4.7389,  ..., -3.0967, -3.5594, -3.4670],\n",
      "        [-3.1634, -3.8503, -4.6526,  ..., -2.4343, -2.6496, -2.7823],\n",
      "        [-2.8878, -3.4747, -4.8224,  ..., -2.5756, -2.5007, -2.7433],\n",
      "        ...,\n",
      "        [-0.2473,  0.0616,  0.4944,  ..., -0.8849, -1.0255, -0.9458],\n",
      "        [-0.1621,  0.0802,  0.1030,  ..., -0.9531, -0.9674, -0.9041],\n",
      "        [-0.2025, -0.1149,  0.0338,  ..., -0.2389, -0.2379, -0.1873]])\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0])\n",
    "print(y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a258aa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([80, 501, 20])\n",
      "torch.Size([80])\n"
     ]
    }
   ],
   "source": [
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048f9e76",
   "metadata": {},
   "source": [
    "## Load model\n",
    "\n",
    "1. define model under the folder models\n",
    "2. import and define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63cd2358",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_CRDNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(simple_CRDNN, self).__init__()\n",
    "        \n",
    "        '''\n",
    "        self.conv1 = CNN_2d_block(\n",
    "            in_channels = 1,\n",
    "            out_channels = 4,\n",
    "            kernel_size = (5, 5),\n",
    "            stride = (2, 2),\n",
    "            padding = (2, 2),\n",
    "            pooling = 'avg',\n",
    "            pooling_kernel_size = (2, 2),\n",
    "            pooling_stride = (2, 2),\n",
    "            pooling_padding = 0,\n",
    "            activation = 'ReLU',\n",
    "            batch_norm = True \n",
    "            \n",
    "        )\n",
    "        \n",
    "        self.conv2 = CNN_2d_block(\n",
    "            in_channels = 4,\n",
    "            out_channels = 8,\n",
    "            kernel_size = (5, 5),\n",
    "            stride = (1, 1),\n",
    "            padding = (2, 2),\n",
    "            pooling = 'max',\n",
    "            pooling_kernel_size = (2, 2),\n",
    "            pooling_stride = (2, 2),\n",
    "            pooling_padding = 0,\n",
    "            activation = 'ReLU',\n",
    "            batch_norm = True \n",
    "            \n",
    "        )\n",
    "        '''\n",
    "        \n",
    "        self.LSTM = nn.LSTM(input_size=20, hidden_size=40, num_layers=8, dropout=0.15, batch_first=True)\n",
    "        self.MLP = MLP(40, 4, [100])\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        # out = self.conv1(x)\n",
    "        # out = self.conv2(out)\n",
    "        # out = torch.flatten(torch.transpose(out, 1, 2), 2)\n",
    "        out, _ = self.LSTM(out)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.MLP(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce695936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eg. MLP\n",
    "model = simple_CRDNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "39f397c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_feat = X_train.shape[2]\n",
    "n_time = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d698407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a = X_train[:10]#.reshape((-1, 1, n_time, n_feat))\n",
    "pred = model(X_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcd3b08",
   "metadata": {},
   "source": [
    "## Define loss and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9182ba02",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.05\n",
    "batch_size = 10\n",
    "num_epoch = 10\n",
    "model_name = 'CRNN'\n",
    "saved_model_name = 'saved_models/saved_' + model_name + '_wave.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bf8fb0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941b60f0",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "use trainers.SGD_trainer.train or define a trainer\n",
    "\n",
    "parameters of SGD_trainer.train\n",
    "- model\n",
    "- train_array: a tuple (X_train, y_train, X_val, y_val)\n",
    "- loss\n",
    "- optimizer\n",
    "- batch_size\n",
    "- num_epoch\n",
    "- device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ddad209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([640, 501, 20])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.26 GiB (GPU 0; 4.00 GiB total capacity; 504.13 MiB already allocated; 650.48 MiB free; 880.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m X_val_2d \u001b[38;5;241m=\u001b[39m X_val\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, n_time, n_feat))\n\u001b[1;32m----> 4\u001b[0m training_loss_array, training_accuracy_array, validation_loss_array, validation_accuracy_array \u001b[38;5;241m=\u001b[39m \u001b[43mtrainers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSGD_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                                                                                                            \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Documents\\COMP 6321\\project\\music_genre_classification\\trainers\\SGD_trainer.py:43\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, training_array, loss, optimizer, batch_size, num_epoch, device)\u001b[0m\n\u001b[0;32m     41\u001b[0m training_loss_array\u001b[38;5;241m.\u001b[39mappend(l\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     42\u001b[0m validation_loss_array\u001b[38;5;241m.\u001b[39mappend(loss(model(X_val), y_val)\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m---> 43\u001b[0m training_accuracy_array\u001b[38;5;241m.\u001b[39mappend(\u001b[43mcal_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     44\u001b[0m validation_accuracy_array\u001b[38;5;241m.\u001b[39mappend(cal_accuracy(model, X_val, y_val)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     45\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32mD:\\Documents\\COMP 6321\\project\\music_genre_classification\\loggers\\trainer_loggers.py:13\u001b[0m, in \u001b[0;36mcal_accuracy\u001b[1;34m(model, X, y, onehot)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcal_accuracy\u001b[39m(model, X, y, onehot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 13\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     _, pred_ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(pred, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m onehot:\n",
      "File \u001b[1;32mD:\\Program\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [53]\u001b[0m, in \u001b[0;36msimple_CRDNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     43\u001b[0m out \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# out = self.conv1(x)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# out = self.conv2(out)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# out = torch.flatten(torch.transpose(out, 1, 2), 2)\u001b[39;00m\n\u001b[1;32m---> 47\u001b[0m out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLSTM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m out \u001b[38;5;241m=\u001b[39m out[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n\u001b[0;32m     49\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMLP(out)\n",
      "File \u001b[1;32mD:\\Program\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32mD:\\Program\\anaconda\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    759\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 761\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    762\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    764\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    765\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.26 GiB (GPU 0; 4.00 GiB total capacity; 504.13 MiB already allocated; 650.48 MiB free; 880.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "X_train_2d = X_train.reshape((-1, 1, n_time, n_feat))\n",
    "print(X_train.shape)\n",
    "X_val_2d = X_val.reshape((-1, 1, n_time, n_feat))\n",
    "training_loss_array, training_accuracy_array, validation_loss_array, validation_accuracy_array = trainers.SGD_trainer.train(model, (X_train, y_train, X_val, y_val), \n",
    "                                                                                                                            loss, optimizer, batch_size=batch_size, num_epoch=num_epoch, device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e687bd",
   "metadata": {},
   "source": [
    "## Plot\n",
    "\n",
    "plot_numerical_arrays: plot multiple arrays with the same length\n",
    "\n",
    "parameters:\n",
    "- num_arrays: numerical arrays with the same length\n",
    "- labels: labels of each array(with the same order of num_arrays)\n",
    "- xlabel\n",
    "- ylabel\n",
    "- title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f272c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numerical_arrays([training_loss_array, validation_loss_array], ['training loss', 'validation loss'], \n",
    "                      xlabel='batches', ylabel='loss', title='train and validation losses for logistic regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c948f6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_numerical_arrays([training_accuracy_array, validation_accuracy_array], ['training accuracy', 'validation accuracy'], \n",
    "                      xlabel='batches', ylabel='accuracy', title='train and validation accuracies for logistic regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580bd41e",
   "metadata": {},
   "source": [
    "## Save model\n",
    "\n",
    "Save model in 'saved_models/saved_modelname_wave.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d90ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), saved_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3918c6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04594c6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
